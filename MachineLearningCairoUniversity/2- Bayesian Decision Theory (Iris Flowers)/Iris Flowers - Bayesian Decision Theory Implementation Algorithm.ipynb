{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive bayes \n",
    "\n",
    "It is the most widely used algorithm of Bayesian Decision Theory for classification a supervised learning data, it depends on using probability to make predections in machine learning, Bayes’ theorem states the following relationship:\n",
    "\n",
    "$$ P(class|data) = \\frac{P(data|class) * P(class)}{ P(data)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load iris flowers data \n",
    "\n",
    "The Iris flower data set is a multivariate data set introduced by the British statistician and biologist Ronald Fisher in his 1936 paper The use of multiple measurements in taxonomic problems. It is sometimes called Anderson's Iris data set because Edgar Anderson collected the data to quantify the morphologic variation of Iris flowers of three related species. The data set consists of 50 samples from each of three species of Iris (Iris Setosa, Iris virginica, and Iris versicolor). Four features were measured from each sample: the length and the width of the sepals and petals, in centimeters.\n",
    "\n",
    "This dataset became a typical test case for many statistical classification techniques in machine learning such as support vector machines and Naive Bayes\n",
    "\n",
    "Reference : https://www.kaggle.com/arshid/iris-flower-dataset#IRIS.csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['5.1', '3.5', '1.4', '0.2', 'setosa'],\n",
       " ['4.9', '3.0', '1.4', '0.2', 'setosa'],\n",
       " ['4.7', '3.2', '1.3', '0.2', 'setosa'],\n",
       " ['4.6', '3.1', '1.5', '0.2', 'setosa'],\n",
       " ['5.0', '3.6', '1.4', '0.2', 'setosa'],\n",
       " ['5.4', '3.9', '1.7', '0.4', 'setosa'],\n",
       " ['4.6', '3.4', '1.4', '0.3', 'setosa'],\n",
       " ['5.0', '3.4', '1.5', '0.2', 'setosa'],\n",
       " ['4.4', '2.9', '1.4', '0.2', 'setosa'],\n",
       " ['4.9', '3.1', '1.5', '0.1', 'setosa']]"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes On The Iris Dataset\n",
    "from csv import reader\n",
    "from random import seed\n",
    "from random import randrange\n",
    "from math import sqrt\n",
    "from math import exp\n",
    "from math import pi\n",
    "\n",
    "# Load a CSV file\n",
    "def load_csv(filename):\n",
    "    dataset = list()\n",
    "    with open(filename, 'r') as file:\n",
    "        csv_reader = reader(file)\n",
    "        for row in csv_reader:\n",
    "            if not row:\n",
    "                continue\n",
    "            dataset.append(row)\n",
    "    return dataset\n",
    "\n",
    "seed(1)\n",
    "filename = 'irisflowers.csv'\n",
    "dataset = load_csv(filename)\n",
    "dataset[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'virginica': 0, 'versicolor': 1, 'setosa': 2}"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert string column to float\n",
    "def str_column_to_float(dataset, column):\n",
    "    for row in dataset:\n",
    "        row[column] = float(row[column].strip())\n",
    "\n",
    "# Convert string column to integer\n",
    "def str_column_to_int(dataset, column):\n",
    "    class_values = [row[column] for row in dataset]\n",
    "    unique = set(class_values)\n",
    "    lookup = dict()\n",
    "    for i, value in enumerate(unique):\n",
    "        lookup[value] = i\n",
    "    for row in dataset:\n",
    "        row[column] = lookup[row[column]]\n",
    "    return lookup\n",
    "\n",
    "for i in range(len(dataset[0])-1):\n",
    "    str_column_to_float(dataset, i)\n",
    "    \n",
    "# convert class column to integers\n",
    "str_column_to_int(dataset, len(dataset[0])-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm Implementation \n",
    "\n",
    "### 1- Seperate by class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: [[5.0, 3.3, 1.4, 0.2, 2],\n",
       "  [5.0, 3.5, 1.3, 0.3, 2],\n",
       "  [4.9, 3.1, 1.5, 0.1, 2],\n",
       "  [4.4, 2.9, 1.4, 0.2, 2],\n",
       "  [5.0, 3.5, 1.6, 0.6, 2],\n",
       "  [5.7, 3.8, 1.7, 0.3, 2],\n",
       "  [5.1, 3.7, 1.5, 0.4, 2],\n",
       "  [4.6, 3.4, 1.4, 0.3, 2],\n",
       "  [5.5, 4.2, 1.4, 0.2, 2],\n",
       "  [5.1, 3.5, 1.4, 0.3, 2],\n",
       "  [5.0, 3.2, 1.2, 0.2, 2],\n",
       "  [5.8, 4.0, 1.2, 0.2, 2],\n",
       "  [5.2, 4.1, 1.5, 0.1, 2],\n",
       "  [5.4, 3.7, 1.5, 0.2, 2],\n",
       "  [4.5, 2.3, 1.3, 0.3, 2],\n",
       "  [5.0, 3.0, 1.6, 0.2, 2],\n",
       "  [5.1, 3.4, 1.5, 0.2, 2],\n",
       "  [4.8, 3.0, 1.4, 0.3, 2],\n",
       "  [5.1, 3.8, 1.5, 0.3, 2],\n",
       "  [5.4, 3.4, 1.7, 0.2, 2],\n",
       "  [4.3, 3.0, 1.1, 0.1, 2],\n",
       "  [4.8, 3.4, 1.6, 0.2, 2],\n",
       "  [4.6, 3.2, 1.4, 0.2, 2],\n",
       "  [5.1, 3.8, 1.6, 0.2, 2],\n",
       "  [4.6, 3.6, 1.0, 0.2, 2],\n",
       "  [5.4, 3.4, 1.5, 0.4, 2],\n",
       "  [5.0, 3.6, 1.4, 0.2, 2],\n",
       "  [5.5, 3.5, 1.3, 0.2, 2],\n",
       "  [4.4, 3.0, 1.3, 0.2, 2],\n",
       "  [4.4, 3.2, 1.3, 0.2, 2],\n",
       "  [5.7, 4.4, 1.5, 0.4, 2],\n",
       "  [5.1, 3.3, 1.7, 0.5, 2],\n",
       "  [4.8, 3.0, 1.4, 0.1, 2],\n",
       "  [4.7, 3.2, 1.3, 0.2, 2],\n",
       "  [4.9, 3.1, 1.5, 0.1, 2],\n",
       "  [5.1, 3.8, 1.9, 0.4, 2],\n",
       "  [4.7, 3.2, 1.6, 0.2, 2],\n",
       "  [5.2, 3.4, 1.4, 0.2, 2],\n",
       "  [5.2, 3.5, 1.5, 0.2, 2],\n",
       "  [5.3, 3.7, 1.5, 0.2, 2],\n",
       "  [4.9, 3.0, 1.4, 0.2, 2],\n",
       "  [4.6, 3.1, 1.5, 0.2, 2],\n",
       "  [5.4, 3.9, 1.7, 0.4, 2],\n",
       "  [5.0, 3.4, 1.6, 0.4, 2],\n",
       "  [5.1, 3.5, 1.4, 0.2, 2],\n",
       "  [5.0, 3.4, 1.5, 0.2, 2],\n",
       "  [4.8, 3.4, 1.9, 0.2, 2],\n",
       "  [4.8, 3.1, 1.6, 0.2, 2],\n",
       "  [5.4, 3.9, 1.3, 0.4, 2],\n",
       "  [4.9, 3.1, 1.5, 0.1, 2]],\n",
       " 1: [[4.9, 2.4, 3.3, 1.0, 1],\n",
       "  [6.8, 2.8, 4.8, 1.4, 1],\n",
       "  [5.4, 3.0, 4.5, 1.5, 1],\n",
       "  [5.5, 2.6, 4.4, 1.2, 1],\n",
       "  [5.6, 2.7, 4.2, 1.3, 1],\n",
       "  [6.1, 3.0, 4.6, 1.4, 1],\n",
       "  [5.2, 2.7, 3.9, 1.4, 1],\n",
       "  [5.6, 3.0, 4.5, 1.5, 1],\n",
       "  [6.7, 3.0, 5.0, 1.7, 1],\n",
       "  [6.0, 2.2, 4.0, 1.0, 1],\n",
       "  [6.1, 2.8, 4.7, 1.2, 1],\n",
       "  [6.4, 2.9, 4.3, 1.3, 1],\n",
       "  [6.3, 2.5, 4.9, 1.5, 1],\n",
       "  [5.0, 2.0, 3.5, 1.0, 1],\n",
       "  [5.7, 2.8, 4.5, 1.3, 1],\n",
       "  [5.7, 2.9, 4.2, 1.3, 1],\n",
       "  [6.9, 3.1, 4.9, 1.5, 1],\n",
       "  [5.0, 2.3, 3.3, 1.0, 1],\n",
       "  [5.6, 3.0, 4.1, 1.3, 1],\n",
       "  [5.1, 2.5, 3.0, 1.1, 1],\n",
       "  [6.0, 2.9, 4.5, 1.5, 1],\n",
       "  [5.7, 3.0, 4.2, 1.2, 1],\n",
       "  [5.7, 2.6, 3.5, 1.0, 1],\n",
       "  [6.4, 3.2, 4.5, 1.5, 1],\n",
       "  [5.9, 3.0, 4.2, 1.5, 1],\n",
       "  [7.0, 3.2, 4.7, 1.4, 1],\n",
       "  [6.6, 3.0, 4.4, 1.4, 1],\n",
       "  [6.0, 3.4, 4.5, 1.6, 1],\n",
       "  [5.5, 2.5, 4.0, 1.3, 1],\n",
       "  [5.6, 2.9, 3.6, 1.3, 1],\n",
       "  [5.5, 2.4, 3.8, 1.1, 1],\n",
       "  [5.8, 2.7, 3.9, 1.2, 1],\n",
       "  [6.1, 2.8, 4.0, 1.3, 1],\n",
       "  [6.7, 3.1, 4.7, 1.5, 1],\n",
       "  [5.9, 3.2, 4.8, 1.8, 1],\n",
       "  [6.1, 2.9, 4.7, 1.4, 1],\n",
       "  [6.3, 3.3, 4.7, 1.6, 1],\n",
       "  [5.8, 2.7, 4.1, 1.0, 1],\n",
       "  [5.8, 2.6, 4.0, 1.2, 1],\n",
       "  [6.5, 2.8, 4.6, 1.5, 1],\n",
       "  [6.3, 2.3, 4.4, 1.3, 1],\n",
       "  [5.6, 2.5, 3.9, 1.1, 1],\n",
       "  [6.0, 2.7, 5.1, 1.6, 1],\n",
       "  [5.5, 2.4, 3.7, 1.0, 1],\n",
       "  [6.6, 2.9, 4.6, 1.3, 1],\n",
       "  [6.2, 2.2, 4.5, 1.5, 1],\n",
       "  [5.7, 2.8, 4.1, 1.3, 1],\n",
       "  [5.5, 2.3, 4.0, 1.3, 1],\n",
       "  [6.2, 2.9, 4.3, 1.3, 1],\n",
       "  [6.7, 3.1, 4.4, 1.4, 1]],\n",
       " 0: [[6.3, 2.8, 5.1, 1.5, 0],\n",
       "  [6.8, 3.2, 5.9, 2.3, 0],\n",
       "  [6.0, 3.0, 4.8, 1.8, 0],\n",
       "  [6.1, 3.0, 4.9, 1.8, 0],\n",
       "  [6.4, 2.8, 5.6, 2.1, 0],\n",
       "  [6.4, 2.8, 5.6, 2.2, 0],\n",
       "  [6.5, 3.0, 5.8, 2.2, 0],\n",
       "  [7.1, 3.0, 5.9, 2.1, 0],\n",
       "  [6.5, 3.0, 5.2, 2.0, 0],\n",
       "  [7.4, 2.8, 6.1, 1.9, 0],\n",
       "  [7.7, 2.6, 6.9, 2.3, 0],\n",
       "  [7.6, 3.0, 6.6, 2.1, 0],\n",
       "  [7.3, 2.9, 6.3, 1.8, 0],\n",
       "  [4.9, 2.5, 4.5, 1.7, 0],\n",
       "  [7.2, 3.2, 6.0, 1.8, 0],\n",
       "  [7.2, 3.0, 5.8, 1.6, 0],\n",
       "  [5.9, 3.0, 5.1, 1.8, 0],\n",
       "  [6.1, 2.6, 5.6, 1.4, 0],\n",
       "  [7.7, 2.8, 6.7, 2.0, 0],\n",
       "  [6.3, 3.3, 6.0, 2.5, 0],\n",
       "  [6.2, 3.4, 5.4, 2.3, 0],\n",
       "  [6.3, 2.7, 4.9, 1.8, 0],\n",
       "  [6.3, 2.5, 5.0, 1.9, 0],\n",
       "  [6.4, 2.7, 5.3, 1.9, 0],\n",
       "  [7.2, 3.6, 6.1, 2.5, 0],\n",
       "  [6.3, 3.4, 5.6, 2.4, 0],\n",
       "  [6.3, 2.9, 5.6, 1.8, 0],\n",
       "  [6.0, 2.2, 5.0, 1.5, 0],\n",
       "  [7.7, 3.0, 6.1, 2.3, 0],\n",
       "  [6.9, 3.1, 5.4, 2.1, 0],\n",
       "  [7.7, 3.8, 6.7, 2.2, 0],\n",
       "  [5.8, 2.7, 5.1, 1.9, 0],\n",
       "  [6.5, 3.0, 5.5, 1.8, 0],\n",
       "  [6.7, 3.1, 5.6, 2.4, 0],\n",
       "  [7.9, 3.8, 6.4, 2.0, 0],\n",
       "  [5.6, 2.8, 4.9, 2.0, 0],\n",
       "  [5.7, 2.5, 5.0, 2.0, 0],\n",
       "  [6.7, 2.5, 5.8, 1.8, 0],\n",
       "  [6.9, 3.1, 5.1, 2.3, 0],\n",
       "  [6.7, 3.3, 5.7, 2.5, 0],\n",
       "  [6.8, 3.0, 5.5, 2.1, 0],\n",
       "  [5.8, 2.7, 5.1, 1.9, 0],\n",
       "  [6.4, 3.1, 5.5, 1.8, 0],\n",
       "  [5.8, 2.8, 5.1, 2.4, 0],\n",
       "  [6.5, 3.2, 5.1, 2.0, 0],\n",
       "  [6.7, 3.3, 5.7, 2.1, 0],\n",
       "  [6.9, 3.2, 5.7, 2.3, 0],\n",
       "  [6.4, 3.2, 5.3, 2.3, 0],\n",
       "  [6.2, 2.8, 4.8, 1.8, 0],\n",
       "  [6.7, 3.0, 5.2, 2.3, 0]]}"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the dataset by class values, returns a dictionary\n",
    "def separate_by_class(dataset):\n",
    "    separated = dict()\n",
    "    for i in range(len(dataset)):\n",
    "        vector = dataset[i]\n",
    "        class_value = vector[-1]\n",
    "        if (class_value not in separated):\n",
    "            separated[class_value] = list()\n",
    "        separated[class_value].append(vector)\n",
    "    return separated\n",
    "separate_by_class(dataset)\n",
    "# those three functions can make the seperation too\n",
    "# df1 = df[df['species'].isin([1])]  - this function will return all of the rows containing the desired value (string or integer)- \n",
    "# df1 = df[df['species'].str.contains(\"setosa\")] - this function will return all of the rows containing the desired value (string)-\n",
    "#dfs = dict(tuple(df.groupby('species'))) # - this function will return grouped tables when you call it by \n",
    "#dfs[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2- Summarize data set\n",
    "\n",
    "Get some statistical calculation like mean:\n",
    "\n",
    "$$ mean(column) = \\frac{sum(column)}{lenght(column)} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean of a list of numbers\n",
    "def mean(numbers):\n",
    "    return sum(numbers)/float(len(numbers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the standard deviation:\n",
    "\n",
    "$$ stdev(column) =  \\sqrt {\\frac {\\sum_ {i=1}^{N} (column(i)-Mean)^2} {N-1} } $$\n",
    "\n",
    "**where N is the length of the column** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the standard deviation of a list of numbers\n",
    "def stdev(numbers):\n",
    "    avg = mean(numbers)\n",
    "    variance = sum([(x-avg)**2 for x in numbers]) / float(len(numbers)-1)\n",
    "    return sqrt(variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "then we can implement our dataset summarization for each column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5.843333333333335, 0.8280661279778632, 150),\n",
       " (3.054, 0.4335943113621738, 150),\n",
       " (3.758666666666667, 1.7644204199522624, 150),\n",
       " (1.198666666666667, 0.7631607417008416, 150)]"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the mean, stdev and count for each column in a dataset\n",
    "def summarize_dataset(dataset):\n",
    "    summaries = [(mean(column), stdev(column), len(column)) for column in zip(*dataset)]\n",
    "    del(summaries[-1])\n",
    "    return summaries\n",
    "summarize_dataset(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3- Summarize data set by Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: [(5.005999999999999, 0.35248968721345114, 50),\n",
       "  (3.418, 0.3810243979546911, 50),\n",
       "  (1.4639999999999997, 0.17351115943644538, 50),\n",
       "  (0.24399999999999988, 0.10720950308167837, 50)],\n",
       " 1: [(5.936, 0.5161711470638636, 50),\n",
       "  (2.7700000000000005, 0.31379832337841135, 50),\n",
       "  (4.26, 0.46991097723995806, 50),\n",
       "  (1.3259999999999998, 0.197752680004544, 50)],\n",
       " 0: [(6.587999999999998, 0.6358795932744322, 50),\n",
       "  (2.9739999999999993, 0.32249663817263746, 50),\n",
       "  (5.552, 0.5518946956639835, 50),\n",
       "  (2.0259999999999994, 0.27465005563666733, 50)]}"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split dataset by class then calculate statistics for each row\n",
    "def summarize_by_class(dataset):\n",
    "    separated = separate_by_class(dataset)\n",
    "    summaries = dict()\n",
    "    for class_value, rows in separated.items():\n",
    "        summaries[class_value] = summarize_dataset(rows)\n",
    "    return summaries\n",
    "summarize_by_class(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4- Gaussian probability density function\n",
    "\n",
    "Calculating the probability or likelihood of observing a given real-value is difficult.\n",
    "\n",
    "One way we can do this is to assume that the feature values are drawn from a distribution, such as a bell curve or Gaussian distribution.\n",
    "\n",
    "A Gaussian distribution can be summarized using only two numbers: the **mean** and the **standard deviation**. Therefore, with a little math, we can estimate the probability of a given value, and can be calculated as:\n",
    "\n",
    "$$ f(x) = \\frac{1}{\\sqrt{2\\pi} * stdev} e^{\\frac{-(x-mean)^{2}}{2*stdev^{2}}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Gaussian probability distribution function for x\n",
    "def calculate_probability(x, mean, stdev):\n",
    "    exponent = exp(-((x-mean)**2 / (2 * stdev**2 )))\n",
    "    return (1 / (sqrt(2 * pi) * stdev)) * exponent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-Class Probabilities\n",
    "\n",
    "Now it is time to use the statistics calculated from our training data to calculate probabilities for new data.\n",
    "\n",
    "Probabilities are calculated separately for each class. This means that we first calculate the probability that a new piece of data belongs to the first class, then calculate probabilities that it belongs to the second class, and so on for all the classes.\n",
    "\n",
    "The probability that a piece of data belongs to a class is calculated as follows:\n",
    "\n",
    "$$ P(class|data) = P(X|class) * P(class) $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the probabilities of predicting each class for a given row\n",
    "def calculate_class_probabilities(summaries, row):\n",
    "    total_rows = sum([summaries[label][0][2] for label in summaries])\n",
    "    probabilities = dict()\n",
    "    for class_value, class_summaries in summaries.items():\n",
    "        probabilities[class_value] = summaries[class_value][0][2]/float(total_rows)\n",
    "        for i in range(len(class_summaries)):\n",
    "            mean, stdev, _ = class_summaries[i]\n",
    "            probabilities[class_value] *= calculate_probability(row[i], mean, stdev)\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Fisher–Yates shuffle Algorithm \n",
    "# to shuffle a list \n",
    "for i in range(len(dataset)-1, 0, -1): \n",
    "      \n",
    "    # Pick a random index from 0 to i  \n",
    "    j = random.randint(0, i + 1)  \n",
    "    \n",
    "    # Swap arr[i] with the element at random index  \n",
    "    dataset[i], dataset[j] = dataset[j], dataset[i] \n",
    "\n",
    "    \n",
    "# Split a dataset into k folds\n",
    "def cross_validation_split(dataset, n_folds):\n",
    "    dataset_split = list()\n",
    "    dataset_copy = list(dataset)\n",
    "    fold_size = int(len(dataset) / n_folds)\n",
    "    for _ in range(n_folds):\n",
    "        fold = list()\n",
    "        while len(fold) < fold_size:\n",
    "            index = randrange(len(dataset_copy))\n",
    "            fold.append(dataset_copy.pop(index))\n",
    "        dataset_split.append(fold)\n",
    "    return dataset_split\n",
    "dataset_split = cross_validation_split(dataset,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = dataset_split[0] + dataset_split[1] + dataset_split[2]\n",
    "test_split = dataset_split[3] + dataset_split[4] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preciction model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the class for a given row\n",
    "def predict(summaries, row):\n",
    "    probabilities = calculate_class_probabilities(summaries, row)\n",
    "    best_label, best_prob = None, -1\n",
    "    for class_value, probability in probabilities.items():\n",
    "        if best_label is None or probability > best_prob:\n",
    "            best_prob = probability\n",
    "            best_label = class_value\n",
    "    return best_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data=[6.2, 2.2, 4.5, 1.5], Predicted: 1 , and the right prediction: 1\n",
      "Data=[7.0, 3.2, 4.7, 1.4], Predicted: 1 , and the right prediction: 1\n",
      "Data=[6.5, 3.0, 5.2, 2.0], Predicted: 0 , and the right prediction: 0\n",
      "Data=[5.4, 3.4, 1.7, 0.2], Predicted: 2 , and the right prediction: 2\n",
      "Data=[6.3, 2.5, 4.9, 1.5], Predicted: 1 , and the right prediction: 1\n",
      "Data=[5.4, 3.4, 1.5, 0.4], Predicted: 2 , and the right prediction: 2\n",
      "Data=[5.7, 2.8, 4.5, 1.3], Predicted: 1 , and the right prediction: 1\n",
      "Data=[6.3, 3.3, 6.0, 2.5], Predicted: 0 , and the right prediction: 0\n",
      "Data=[6.9, 3.2, 5.7, 2.3], Predicted: 0 , and the right prediction: 0\n",
      "Data=[6.3, 2.7, 4.9, 1.8], Predicted: 0 , and the right prediction: 0\n",
      "Data=[7.3, 2.9, 6.3, 1.8], Predicted: 0 , and the right prediction: 0\n",
      "Data=[5.6, 2.7, 4.2, 1.3], Predicted: 1 , and the right prediction: 1\n",
      "Data=[5.6, 2.9, 3.6, 1.3], Predicted: 1 , and the right prediction: 1\n",
      "Data=[7.2, 3.2, 6.0, 1.8], Predicted: 0 , and the right prediction: 0\n",
      "Data=[5.9, 3.0, 5.1, 1.8], Predicted: 0 , and the right prediction: 0\n",
      "Data=[5.5, 2.6, 4.4, 1.2], Predicted: 1 , and the right prediction: 1\n",
      "Data=[5.0, 3.4, 1.5, 0.2], Predicted: 2 , and the right prediction: 2\n",
      "Data=[5.8, 2.7, 5.1, 1.9], Predicted: 0 , and the right prediction: 0\n",
      "Data=[5.8, 2.7, 3.9, 1.2], Predicted: 1 , and the right prediction: 1\n",
      "Data=[5.6, 3.0, 4.1, 1.3], Predicted: 1 , and the right prediction: 1\n",
      "Data=[7.7, 2.6, 6.9, 2.3], Predicted: 0 , and the right prediction: 0\n",
      "Data=[5.1, 2.5, 3.0, 1.1], Predicted: 1 , and the right prediction: 1\n",
      "Data=[4.4, 2.9, 1.4, 0.2], Predicted: 2 , and the right prediction: 2\n",
      "Data=[4.8, 3.1, 1.6, 0.2], Predicted: 2 , and the right prediction: 2\n",
      "Data=[6.4, 2.9, 4.3, 1.3], Predicted: 1 , and the right prediction: 1\n",
      "Data=[6.2, 2.9, 4.3, 1.3], Predicted: 1 , and the right prediction: 1\n",
      "Data=[6.1, 2.8, 4.0, 1.3], Predicted: 1 , and the right prediction: 1\n",
      "Data=[5.7, 2.8, 4.1, 1.3], Predicted: 1 , and the right prediction: 1\n",
      "Data=[5.1, 3.5, 1.4, 0.3], Predicted: 2 , and the right prediction: 2\n",
      "Data=[5.2, 2.7, 3.9, 1.4], Predicted: 1 , and the right prediction: 1\n",
      "Data=[5.4, 3.0, 4.5, 1.5], Predicted: 1 , and the right prediction: 1\n",
      "Data=[5.1, 3.8, 1.6, 0.2], Predicted: 2 , and the right prediction: 2\n",
      "Data=[5.7, 4.4, 1.5, 0.4], Predicted: 2 , and the right prediction: 2\n",
      "Data=[6.4, 2.8, 5.6, 2.1], Predicted: 0 , and the right prediction: 0\n",
      "Data=[5.9, 3.2, 4.8, 1.8], Predicted: 0 , and the right prediction: 1\n",
      "Data=[5.4, 3.9, 1.3, 0.4], Predicted: 2 , and the right prediction: 2\n",
      "Data=[5.7, 2.5, 5.0, 2.0], Predicted: 0 , and the right prediction: 0\n",
      "Data=[5.8, 2.8, 5.1, 2.4], Predicted: 0 , and the right prediction: 0\n",
      "Data=[6.7, 3.0, 5.0, 1.7], Predicted: 0 , and the right prediction: 1\n",
      "Data=[6.5, 3.0, 5.5, 1.8], Predicted: 0 , and the right prediction: 0\n",
      "Data=[4.6, 3.6, 1.0, 0.2], Predicted: 2 , and the right prediction: 2\n",
      "Data=[4.4, 3.0, 1.3, 0.2], Predicted: 2 , and the right prediction: 2\n",
      "Data=[5.3, 3.7, 1.5, 0.2], Predicted: 2 , and the right prediction: 2\n",
      "Data=[6.4, 3.1, 5.5, 1.8], Predicted: 0 , and the right prediction: 0\n",
      "Data=[6.5, 3.2, 5.1, 2.0], Predicted: 0 , and the right prediction: 0\n",
      "Data=[6.3, 2.9, 5.6, 1.8], Predicted: 0 , and the right prediction: 0\n",
      "Data=[6.4, 2.8, 5.6, 2.2], Predicted: 0 , and the right prediction: 0\n",
      "Data=[6.5, 3.0, 5.8, 2.2], Predicted: 0 , and the right prediction: 0\n",
      "Data=[7.2, 3.0, 5.8, 1.6], Predicted: 0 , and the right prediction: 0\n",
      "Data=[4.9, 2.4, 3.3, 1.0], Predicted: 1 , and the right prediction: 1\n",
      "Data=[6.2, 3.4, 5.4, 2.3], Predicted: 0 , and the right prediction: 0\n",
      "Data=[4.9, 2.5, 4.5, 1.7], Predicted: 1 , and the right prediction: 0\n",
      "Data=[6.0, 2.9, 4.5, 1.5], Predicted: 1 , and the right prediction: 1\n",
      "Data=[6.7, 3.3, 5.7, 2.1], Predicted: 0 , and the right prediction: 0\n",
      "Data=[5.8, 2.7, 5.1, 1.9], Predicted: 0 , and the right prediction: 0\n",
      "Data=[7.2, 3.6, 6.1, 2.5], Predicted: 0 , and the right prediction: 0\n",
      "Data=[5.5, 3.5, 1.3, 0.2], Predicted: 2 , and the right prediction: 2\n",
      "Data=[7.7, 2.8, 6.7, 2.0], Predicted: 0 , and the right prediction: 0\n",
      "Data=[5.7, 2.6, 3.5, 1.0], Predicted: 1 , and the right prediction: 1\n",
      "Data=[6.9, 3.1, 5.4, 2.1], Predicted: 0 , and the right prediction: 0\n",
      "accuracy = 95.0\n"
     ]
    }
   ],
   "source": [
    "# Make a prediction with Naive Bayes on Iris Dataset\n",
    "# fit model\n",
    "model = summarize_by_class(train_split)\n",
    "# define a new record\n",
    "accuracy = 0 \n",
    "for i in range (len(test_split)):\n",
    "    row = dataset[i][:-1] \n",
    "    # predict the label\n",
    "    label = predict(model, row)\n",
    "    print('Data=%s, Predicted: %s , and the right prediction: %s' % (row, label , dataset[i][-1]))\n",
    "    if (dataset[i][-1]  == label):\n",
    "        accuracy = accuracy + 1\n",
    "print ('accuracy = %s' % ((accuracy/len(test_split))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
